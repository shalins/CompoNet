{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7074b8d9",
   "metadata": {},
   "source": [
    "# Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2603377b",
   "metadata": {},
   "source": [
    "This python notebook consists of a set of functions that take a JSON input from the `scraper` tool, and get the data into a format that we can serve on the final website. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f169e6fa",
   "metadata": {},
   "source": [
    "## JSON to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff86d2c9",
   "metadata": {},
   "source": [
    "As our input data is currently formatted in JSON, we want to convert that to CSV so we can work with entire columns, and eventually push to a database like PostgreSQL.\n",
    "\n",
    "To avoid corrupting the original data that was collected, place a copy of the data in the convenience folder `./_raw_json` in this directory, and only modify this copied data as you work with the modules in this notebook.\n",
    "\n",
    "The following block of code will go through all the JSON files in the specified directory, flatten them, convert them into CSV's, and save them all to disk in the `./_raw_csv` directory.\n",
    "\n",
    "**NOTE**: This is the only part of the process that's somewhat hardcoded. In order to combine the JSON into a single CSV, the column names have to be consistently named, and its easier to easier to acheive this by edit the JSON's before saving as CSV's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d2d10b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from flatten_json import flatten\n",
    "from tqdm import tqdm\n",
    "\n",
    "JSON_DIR = './_raw_json'\n",
    "CSV_DIR = './_raw_csv'\n",
    "CSV_FINAL = 'all.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6cf6da",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "343f1ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_keys_from_dict(d, to_delete):\n",
    "    if isinstance(to_delete, str):\n",
    "        to_delete = [to_delete]\n",
    "    if isinstance(d, dict):\n",
    "        for single_to_delete in set(to_delete):\n",
    "            if single_to_delete in d:\n",
    "                del d[single_to_delete]\n",
    "        for k, v in d.items():\n",
    "            delete_keys_from_dict(v, to_delete)\n",
    "    elif isinstance(d, list):\n",
    "        for i in d:\n",
    "            delete_keys_from_dict(i, to_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8125279",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19877931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:12<00:00, 18.07s/it]\n"
     ]
    }
   ],
   "source": [
    "for filename in tqdm(os.listdir(JSON_DIR)):\n",
    "    if \".json\" in filename:\n",
    "        with open(f'{JSON_DIR}/{filename}', 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "            # 1. First globally delete all the keys that we don't want.\n",
    "            delete_keys_from_dict(data, ['__typename', 'best_datasheet', 'best_image', 'manufacturer_url'])\n",
    "            \n",
    "            for result in data['data']['search']['results']:\n",
    "                # 2. Within the JSON, flatten the `specs` array from \n",
    "                #    'specs': [{'attribute': {'id': '548',\n",
    "                #                             'name': 'Capacitance' \n",
    "                #                             'shortname': 'capacitance'\n",
    "                #                             '__typename': 'Attribute'\n",
    "                #                            },\n",
    "                #               'display_value': '100 nF'\n",
    "                #              },\n",
    "                #              { ... },\n",
    "                #              { ... },\n",
    "                #              ...\n",
    "                #             ]\n",
    "                #    to\n",
    "                #    'specs': {'capacitance': {'display_value': '100 nF', 'id': '548'},\n",
    "                #              'case_package': {'display_value': 'Radial', 'id': '842'},\n",
    "                #              'depth': {'display_value': '8 mm', 'id': '291'},\n",
    "                #              ...\n",
    "                #             }    \n",
    "                #    and remove some fields that we don't want to include.\n",
    "                spec_json = {}\n",
    "                for spec in result['part']['specs']:\n",
    "                    title = spec['attribute']['shortname']\n",
    "                    spec['attribute']['display_value'] = spec['display_value']\n",
    "                    spec = spec['attribute']\n",
    "                    del spec['shortname']\n",
    "                    del spec['name']\n",
    "                    spec_json[title] = spec\n",
    "                result['part']['specs'] = spec_json\n",
    "\n",
    "\n",
    "                # 3. Remove specific parts of the JSON that we don't want (duplicate fields, etc).\n",
    "                del result['part']['_cache_id']\n",
    "                del result['part']['descriptions']\n",
    "                del result['part']['counts']\n",
    "            \n",
    "            # 4. Run the `flatten` function on each of the parts, place it in a list, and convert \n",
    "            #    to a Pandas DF.\n",
    "            flat = [flatten(d) for d in data['data']['search']['results']]\n",
    "    \n",
    "            df = pd.DataFrame(flat, dtype ='str')\n",
    "            df.to_csv(f\"{CSV_DIR}/{filename.split('.')[0]}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b071302",
   "metadata": {},
   "source": [
    "#### Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6aa506a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./_raw_csv/film.csv', './_raw_csv/mica.csv', './_raw_csv/ceramic.csv', './_raw_csv/aluminum_electrolytic.csv']\n"
     ]
    }
   ],
   "source": [
    "filenames = [f\"{CSV_DIR}/{filename}\" for filename in os.listdir(CSV_DIR) if \"all\" not in filename and \".csv\" in filename]\n",
    "df = pd.concat(map(pd.read_csv, filenames), ignore_index=True)\n",
    "df = df.astype(str)\n",
    "df.to_csv(f\"{CSV_DIR}/{CSV_FINAL}\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471ce95f",
   "metadata": {},
   "source": [
    "## CSV Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f3bca",
   "metadata": {},
   "source": [
    "In this step, we want to take the combined CSV that we generated in the previous step and format it into the final format that we will upload to the PostgreSQL database.\n",
    "\n",
    "We will use a modular approach. For each step of updating the CSV, we will implement a function that takes in a pandas dataframe and outputs another pandas dataframe in the desired format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b1ac143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/21/pp5p0yss3xq_1z5gvfm0shgh0000gn/T/ipykernel_67893/3566771438.py:1: DtypeWarning: Columns (14,16,18,24,26,28,30,36,38,40,44,46,48,50,54,58,60,62,64,66,70,72,74,78,80,82,84,86,88,90,92,94,96,99,101,103,107,109,115,117,119,121,123,125,127,129,131,133,135,141,143,145,147,149,153,155,157,159,161,163,165,167,169,171,173,175,177,179,181,183,185,187,189,191,193,195,197,199,201,203,205,207,209,213,217,219,221,223,225,227,229,231,235,237,239,243,245,247,249,251,253,255,257,259,261,263,265,267,269,271,273,275,277,279,281,283,285,289,291,293,295,297,299,301,303,305,309,311,313,315,317) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'{CSV_DIR}/all.csv', index_col=False)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f'{CSV_DIR}/all.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5292297d",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_float_cols = [\n",
    "    'part_specs_tolerance_display_value', \n",
    "    'part_specs_temperaturecoefficient_display_value', \n",
    "    'part_specs_maxjunctiontemperature_display_value', \n",
    "    'part_specs_maxoperatingtemperature_display_value', \n",
    "    'part_specs_minoperatingtemperature_display_value', \n",
    "    'part_specs_dissipationfactor_display_value', \n",
    "    'part_specs_failurerate_display_value', \n",
    "    'part_specs_frequencytolerance_display_value', \n",
    "    'part_specs_qfactor_display_value', \n",
    "    'part_specs_frequencystability_display_value', \n",
    "    'part_specs_viewingangle_display_value', \n",
    "    'part_specs_accuracy_display_value', \n",
    "    'part_specs_speedgrade_display_value', \n",
    "    'part_specs_inductancetolerance_display_value', \n",
    "    'part_specs_ambienttemperaturerangehigh_display_value'\n",
    "]\n",
    "\n",
    "string_to_int_cols = [\n",
    "    'part_specs_numberofpins_display_value', \n",
    "    'part_specs_life_hours__display_value', \n",
    "    'part_specs_numberofelements_display_value', \n",
    "    'part_specs_numberofterminals_display_value', \n",
    "    'part_specs_numberofchannels_display_value', \n",
    "    'part_specs_life_cycles__display_value', \n",
    "    'part_specs_commonmoderejectionratio_display_value', \n",
    "    'part_specs_gainbandwidthproduct_display_value', \n",
    "    'part_specs_numberofcapacitors_display_value', \n",
    "    'part_specs_numberofcircuits_display_value', \n",
    "    'part_specs_numberofi_os_display_value', \n",
    "    'part_specs_numberofleds_display_value', \n",
    "    'part_specs_numberofpositions_display_value'\n",
    "]\n",
    "\n",
    "string_to_base_float_cols = [\n",
    "    'part_specs_capacitance_display_value', \n",
    "    'part_specs_depth_display_value', \n",
    "    'part_specs_height_display_value', \n",
    "    'part_specs_height_seated_max__display_value', \n",
    "    'part_specs_leaddiameter_display_value', \n",
    "    'part_specs_leadpitch_display_value', \n",
    "    'part_specs_length_display_value', \n",
    "    'part_specs_voltage_display_value', \n",
    "    'part_specs_voltagerating_display_value', \n",
    "    'part_specs_voltagerating_ac__display_value', \n",
    "    'part_specs_voltagerating_dc__display_value', \n",
    "    'part_specs_width_display_value', \n",
    "    'part_specs_weight_display_value', \n",
    "    'part_specs_leadlength_display_value', \n",
    "    'part_specs_insulationresistance_display_value', \n",
    "    'part_specs_diameter_display_value', \n",
    "    'part_specs_thickness_display_value', \n",
    "    'part_specs_esr_equivalentseriesresistance__display_value', \n",
    "    'part_specs_pitch_display_value', \n",
    "    'part_specs_resistance_display_value', \n",
    "    'part_specs_dcresistance_dcr__display_value', \n",
    "    'part_specs_inductance_display_value', \n",
    "    'part_specs_maxdccurrent_display_value', \n",
    "    'part_specs_powerrating_display_value', \n",
    "    'part_specs_seriesresistance_display_value', \n",
    "    'part_specs_terminalpitch_display_value', \n",
    "    'part_specs_currentrating_display_value', \n",
    "    'part_specs_characterheight_display_value', \n",
    "    'part_specs_wire_cablediameter_display_value', \n",
    "    'part_specs_ripplecurrent_display_value',\n",
    "    'part_specs_cablelength_display_value', \n",
    "    'part_specs_maxsupplyvoltage_display_value', \n",
    "    'part_specs_minsupplyvoltage_display_value', \n",
    "    'part_specs_voltagegain_display_value', \n",
    "    'part_specs_loadcurrent_display_value', \n",
    "    'part_specs_outputcurrent_display_value', \n",
    "    'part_specs_maxlength_display_value', \n",
    "    'part_specs_maxthickness_display_value', \n",
    "    'part_specs_maxwidth_display_value', \n",
    "    'part_specs_minlength_display_value', \n",
    "    'part_specs_minthickness_display_value', \n",
    "    'part_specs_minwidth_display_value', \n",
    "    'part_specs_insidediameter_display_value', \n",
    "    'part_specs_responsetime_display_value', \n",
    "    'part_specs_nominalsupplycurrent_display_value', \n",
    "    'part_specs_selfresonantfrequency_display_value', \n",
    "    'part_specs_memorysize_display_value', \n",
    "    'part_specs_current_display_value', \n",
    "    'part_specs_maxcurrentrating_display_value', \n",
    "    'part_specs_maxvoltagerating_dc__display_value', \n",
    "    'part_specs_maxoutputcurrent_display_value', \n",
    "    'part_specs_mininputvoltage_display_value', \n",
    "    'part_specs_outputvoltage_display_value', \n",
    "    'part_specs_bandwidth_display_value', \n",
    "    'part_specs_nominalsupplyvoltage_dc__display_value', \n",
    "    'part_specs_dropoutvoltage_display_value', \n",
    "    'part_specs_terminalwidth_display_value', \n",
    "    'part_specs_forwardcurrent_display_value', \n",
    "    'part_specs_forwardvoltage_display_value', \n",
    "    'part_specs_maxrepetitivereversevoltage_vrrm__display_value', \n",
    "    'part_specs_peaknon_repetitivesurgecurrent_display_value', \n",
    "    'part_specs_peakreversecurrent_display_value', \n",
    "    'part_specs_maxfrequency_display_value', \n",
    "    'part_specs_ramsize_display_value', \n",
    "    'part_specs_leakagecurrent_display_value', \n",
    "    'part_specs_testfrequency_display_value', \n",
    "    'part_specs_ripplecurrent_ac__display_value', \n",
    "    'part_specs_impedance_display_value', \n",
    "    'part_specs_holediameter_display_value', \n",
    "    'part_specs_outsidediameter_display_value', \n",
    "    'part_specs_switchingvoltage_display_value',\n",
    "    'part_specs_workingvoltage_display_value', \n",
    "    'part_specs_loadcapacitance_display_value', \n",
    "    'part_specs_operatingsupplyvoltage_display_value', \n",
    "    'part_specs_frequency_display_value', \n",
    "    'part_specs_databuswidth_display_value'\n",
    "    'part_specs_luminousintensity_display_value', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df43e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport compute\n",
    "df = compute.spec_string_to_float(df, cols=string_to_float_cols)\n",
    "df = compute.spec_string_to_int(df, cols=string_to_int_cols)\n",
    "df = compute.spec_string_to_base_float(df, cols=string_to_base_float_cols)\n",
    "\n",
    "\"\"\"\n",
    "The total list of dielectric types from our dataset is:\n",
    "{'Z5F', 'Z5U', 'X8L', 'P2H', 'K2000', 'X7T', 'X0U', 'Y5F', 'X7S', 'X5F', 'Z5T', 'X5R', 'Y5R', 'C0J', 'Y5P', 'X5S', 'S2H', 'Z5P', 'K4000', 'Z7S', 'X6S', 'X8R', 'R3L', 'PP', 'C0H', 'Y5T', 'X5P', 'Y5U', 'R2H', 'Y5V', 'X8G', 'PPS', 'C0G', 'U2J', 'M3K', 'Z5V', 'T3M', 'PET', 'X7R', 'S3N', 'X7U', 'Y5E', 'P3K', 'C0K', 'T2H', 'Mica', 'Y5S', 'X6T', 'X5U', 'NP0'}\n",
    "\"\"\"\n",
    "df = compute.classify_ceramic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20dc99b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5b63e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        NaN\n",
      "1        NaN\n",
      "2        NaN\n",
      "3        NaN\n",
      "4        NaN\n",
      "          ..\n",
      "359969   NaN\n",
      "359970   NaN\n",
      "359971   NaN\n",
      "359972   NaN\n",
      "359973   NaN\n",
      "Name: volume, Length: 359974, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df2 = compute.compute_volume(df)\n",
    "df2.to_csv(\"test_vol.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee52db0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
