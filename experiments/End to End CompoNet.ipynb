{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "231f3184",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: postgres_csv_uploader in /opt/homebrew/lib/python3.9/site-packages (0.1.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.41 in /opt/homebrew/lib/python3.9/site-packages (from postgres_csv_uploader) (1.4.41)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/homebrew/lib/python3.9/site-packages (from postgres_csv_uploader) (1.23.4)\n",
      "Requirement already satisfied: pandas>=1.4.4 in /opt/homebrew/lib/python3.9/site-packages (from postgres_csv_uploader) (1.5.1)\n",
      "Requirement already satisfied: psycopg2>=2.7.7 in /opt/homebrew/lib/python3.9/site-packages (from postgres_csv_uploader) (2.9.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/homebrew/lib/python3.9/site-packages (from pandas>=1.4.4->postgres_csv_uploader) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.9/site-packages (from pandas>=1.4.4->postgres_csv_uploader) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.4.4->postgres_csv_uploader) (1.16.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import psycopg2 as ps\n",
    "\n",
    "!{sys.executable} -m pip install postgres_csv_uploader\n",
    "from postgres_csv_uploader.uploader import PostgresCSVUploader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c97bf52d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: ipdb in /opt/homebrew/lib/python3.9/site-packages (0.13.9)\n",
      "Requirement already satisfied: ipython>=7.17.0 in /opt/homebrew/lib/python3.9/site-packages (from ipdb) (8.4.0)\n",
      "Requirement already satisfied: toml>=0.10.2 in /opt/homebrew/lib/python3.9/site-packages (from ipdb) (0.10.2)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.9/site-packages (from ipdb) (65.4.1)\n",
      "Requirement already satisfied: decorator in /opt/homebrew/lib/python3.9/site-packages (from ipdb) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/homebrew/lib/python3.9/site-packages (from ipython>=7.17.0->ipdb) (3.0.30)\n",
      "Requirement already satisfied: pickleshare in /opt/homebrew/lib/python3.9/site-packages (from ipython>=7.17.0->ipdb) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /opt/homebrew/lib/python3.9/site-packages (from ipython>=7.17.0->ipdb) (0.3.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/homebrew/lib/python3.9/site-packages (from ipython>=7.17.0->ipdb) (2.12.0)\n",
      "Requirement already satisfied: traitlets>=5 in /opt/homebrew/lib/python3.9/site-packages (from ipython>=7.17.0->ipdb) (5.3.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/homebrew/lib/python3.9/site-packages (from ipython>=7.17.0->ipdb) (4.8.0)\n",
      "Requirement already satisfied: backcall in /opt/homebrew/lib/python3.9/site-packages (from ipython>=7.17.0->ipdb) (0.2.0)\n",
      "Requirement already satisfied: appnope in /opt/homebrew/lib/python3.9/site-packages (from ipython>=7.17.0->ipdb) (0.1.3)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/homebrew/lib/python3.9/site-packages (from ipython>=7.17.0->ipdb) (0.1.3)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/homebrew/lib/python3.9/site-packages (from ipython>=7.17.0->ipdb) (0.18.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/homebrew/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.17.0->ipdb) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/homebrew/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.17.0->ipdb) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/homebrew/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.17.0->ipdb) (0.2.5)\n",
      "Requirement already satisfied: executing in /opt/homebrew/lib/python3.9/site-packages (from stack-data->ipython>=7.17.0->ipdb) (0.9.1)\n",
      "Requirement already satisfied: pure-eval in /opt/homebrew/lib/python3.9/site-packages (from stack-data->ipython>=7.17.0->ipdb) (0.2.2)\n",
      "Requirement already satisfied: asttokens in /opt/homebrew/lib/python3.9/site-packages (from stack-data->ipython>=7.17.0->ipdb) (2.0.7)\n",
      "Requirement already satisfied: six in /opt/homebrew/lib/python3.9/site-packages (from asttokens->stack-data->ipython>=7.17.0->ipdb) (1.16.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d175eb52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1696bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from io import StringIO\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import psycopg2 as ps\n",
    "import psycopg2.sql as sql\n",
    "from psycopg2.extensions import connection\n",
    "\n",
    "\n",
    "class PostgresCSVUploader:\n",
    "    def __init__(self, conn: connection):\n",
    "        self.conn = conn\n",
    "        self.data = None\n",
    "        self.buffer = StringIO()\n",
    "        self.py_2_sql_map = {\n",
    "            \"uint8\": \"SMALLINT\",\n",
    "            \"uint16\": \"SMALLINT\",\n",
    "            \"uint32\": \"INTEGER\",\n",
    "            \"uint64\": \"BIGINT\",\n",
    "            \"int\": \"INTEGER\",\n",
    "            \"int8\": \"SMALLINT\",\n",
    "            \"int16\": \"INTEGER\",\n",
    "            \"int32\": \"INTEGER\",\n",
    "            \"int64\": \"BIGINT\",\n",
    "            \"complex128\": \"VARCHAR\",\n",
    "            \"complex64\": \"VARCHAR\",\n",
    "            \"str\": \"VARCHAR\",\n",
    "            \"object\": \"VARCHAR\",\n",
    "            \"category\": \"VARCHAR\",\n",
    "            \"Decimal\": \"NUMERIC\",\n",
    "            \"float\": \"FLOAT\",\n",
    "            \"float16\": \"FLOAT\",\n",
    "            \"float32\": \"FLOAT\",\n",
    "            \"float64\": \"DOUBLE PRECISION\",\n",
    "            \"datetime\": \"TIMESTAMP\",\n",
    "            \"time\": \"TIME\",\n",
    "            \"date\": \"DATE\",\n",
    "            \"datetime64\": \"DATE\",\n",
    "            \"bytes\": \"BYTEA\",\n",
    "            \"void\": \"BYTEA\",\n",
    "            \"bool\": \"BOOLEAN\",\n",
    "            \"timedelta\": \"INTERVAL\",\n",
    "            \"timedelta64\": \"INTERVAL\",\n",
    "            \"list\": \"ARRAY\",\n",
    "            \"dict\": \"JSON\",\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_new_connection(\n",
    "        cls, host: str, user: str, password: str, port: str, database: Optional[str]\n",
    "    ):\n",
    "        conn = ps.connect(\n",
    "            host=host,\n",
    "            database=database if database else user,\n",
    "            user=user,\n",
    "            password=password,\n",
    "            port=port,\n",
    "        )\n",
    "        return cls(conn)\n",
    "\n",
    "    def create_table(\n",
    "        self,\n",
    "        filepath: str,\n",
    "        table: str,\n",
    "        index_col: Optional[str] = None,\n",
    "        datetime_cols: Optional[List[str]] = None,\n",
    "    ) -> None:\n",
    "        cur = self.conn.cursor()\n",
    "        columns = self.create_table_schema(filepath, index_col, datetime_cols)\n",
    "        sanitized_cols = [\n",
    "            sql.Identifier(c[0]).as_string(cur) + f\" {c[1]}\" for c in columns\n",
    "        ]\n",
    "        sanitized_cols[0] += \" PRIMARY KEY\"\n",
    "        delete_query = sql.SQL(\"DROP TABLE IF EXISTS {0};\").format(\n",
    "            sql.Identifier(table)\n",
    "        )\n",
    "        query = sql.SQL(\"CREATE TABLE {0} ({1});\").format(\n",
    "            sql.Identifier(table), sql.SQL(\",\".join(sanitized_cols))\n",
    "        )\n",
    "        cur.execute(delete_query)\n",
    "        cur.execute(query)\n",
    "        return cur.query.decode(\"utf-8\")\n",
    "\n",
    "    def upload(\n",
    "        self,\n",
    "        filepath: str,\n",
    "        table: str,\n",
    "        index_col: Optional[str] = None,\n",
    "        datetime_cols: Optional[List[str]] = None,\n",
    "    ):\n",
    "        \"\"\"Uploads a CSV file as its own table in a Postgres DB\n",
    "\n",
    "        Args:\n",
    "            filepath (str): Path to CSV file\n",
    "            table (str): Table name\n",
    "            index_col (Optional[str], optional): Name of index column. Defaults to\n",
    "            None, in which case a numerical index is used.\n",
    "            datetime_cols (Optional[List[str]], optional): List of column names for\n",
    "            \"datetime\" columns. Defaults to None.\n",
    "        \"\"\"\n",
    "        cur = self.conn.cursor()\n",
    "        self.create_table(filepath, table, index_col, datetime_cols)\n",
    "        self.buffer.seek(0)\n",
    "        # `copy_expert` lets us specify CSV formatting, which is important when columns\n",
    "        # contain commas, or for keeping null values.\n",
    "        cur.copy_expert(f\"COPY {table} FROM STDIN WITH (FORMAT CSV)\", self.buffer)\n",
    "        self.conn.commit()\n",
    "\n",
    "    def create_table_schema(\n",
    "        self,\n",
    "        filepath: str,\n",
    "        index_col: Optional[str] = None,\n",
    "        datetime_cols: Optional[List[str]] = None,\n",
    "    ) -> Dict[str, str]:\n",
    "        \"\"\"Generates a Postgres schema based on the Pandas dtypes of an input CSV file\n",
    "\n",
    "        Args:\n",
    "            filepath (str): Path to CSV file\n",
    "            index_col (Optional[str], optional): Name of index column. Defaults to\n",
    "            None, in which case a numerical index is used.\n",
    "            datetime_cols (Optional[List[str]], optional): List of column names for\n",
    "            \"datetime\" columns. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, str]: Mapping from column name to postgres type name\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(filepath, parse_dates=datetime_cols)\n",
    "        if \"Unnamed: 0\" in df.columns:\n",
    "            df.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "        if not index_col:\n",
    "            df = df.reset_index()\n",
    "            index_col = df.columns[0]\n",
    "        else:\n",
    "            df.insert(0, index_col, df.pop(index_col), allow_duplicates=True)\n",
    "\n",
    "        df = df.infer_objects()\n",
    "        df.to_csv(self.buffer, header=False, index=False)\n",
    "        cols_map = self.map_sql_dtypes(df)\n",
    "        return cols_map\n",
    "\n",
    "    def map_sql_dtypes(self, df: pd.DataFrame) -> List[Tuple[str, str]]:\n",
    "        \"\"\"Given a dataframe, map each of its columns to the appropriate Postgres type\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Input dataframe\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, str]: Mapping from column name to postgres type name\n",
    "        \"\"\"\n",
    "        col_to_pgtype = []\n",
    "        for col in df.columns:\n",
    "            dtype = df[col].dtype.name\n",
    "\n",
    "            if \"time\" in dtype and re.compile(r\"\\[.*\\]$\").search(dtype):\n",
    "                dtype = re.sub(r\"\\[.*\\]$\", \"\", dtype)\n",
    "            col_to_pgtype.append((col, self.py_2_sql_map[dtype]))\n",
    "\n",
    "        return col_to_pgtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3d48e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import signature\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import psycopg2 as ps\n",
    "from psycopg2.extensions import connection\n",
    "import psycopg2.sql as sql\n",
    "import pandas as pd\n",
    "from sqlalchemy.dialects import postgresql\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "import re\n",
    "import csv\n",
    "\n",
    "class PostgresCSVUploader:\n",
    "\n",
    "    def __init__(self, conn: connection):\n",
    "        self.conn = conn\n",
    "        self.data = None\n",
    "        self.buffer = StringIO()\n",
    "        self.py_2_sql_map = {\n",
    "            'uint8': 'SMALLINT', \n",
    "            'uint16': 'SMALLINT', \n",
    "            'uint32': 'INTEGER', \n",
    "            'uint64': 'BIGINT', \n",
    "            'int': 'INTEGER', \n",
    "            'int8': 'SMALLINT', \n",
    "            'int16': 'INTEGER', \n",
    "            'int32': 'INTEGER', \n",
    "            'int64': 'BIGINT', \n",
    "            'complex128': 'VARCHAR', \n",
    "            'complex64': 'VARCHAR', \n",
    "            'str': 'VARCHAR', \n",
    "            'object': 'VARCHAR', \n",
    "            'category': 'VARCHAR', \n",
    "            'Decimal': 'NUMERIC', \n",
    "            'float': 'FLOAT', \n",
    "            'float16': 'FLOAT', \n",
    "            'float32': 'FLOAT', \n",
    "            'float64': 'DOUBLE PRECISION', \n",
    "            'datetime': 'TIMESTAMP', \n",
    "            'time': 'TIME', \n",
    "            'date': 'DATE', \n",
    "            'datetime64': 'DATE', \n",
    "            'bytes': 'BYTEA', \n",
    "            'void': 'BYTEA', \n",
    "            'bool': 'BOOLEAN', \n",
    "            'timedelta': 'INTERVAL', \n",
    "            'timedelta64': 'INTERVAL', \n",
    "            'list': 'ARRAY', \n",
    "            'dict': 'JSON',\n",
    "            }\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def from_new_connection(cls,\n",
    "        host: str,\n",
    "        user: str,\n",
    "        password: str,\n",
    "        port: str,\n",
    "        database: Optional[str]\n",
    "    ):\n",
    "        conn = ps.connect(\n",
    "            host=host,\n",
    "            database=database if database else user,\n",
    "            user=user,\n",
    "            password=password,\n",
    "            port=port\n",
    "        )\n",
    "        return cls(conn)\n",
    "    \n",
    "    def create_table(\n",
    "        self, \n",
    "        filepath: str, \n",
    "        table: str,\n",
    "        index_col: Optional[str] = None,\n",
    "        datetime_cols: Optional[List[str]] = None\n",
    "    ) -> None:\n",
    "        cur = self.conn.cursor()\n",
    "        columns = self.create_table_schema(filepath, index_col, datetime_cols)\n",
    "        sanitized_cols = [sql.Identifier(c[0]).as_string(cur) + f\" {c[1]}\" for c in columns]\n",
    "        sanitized_cols[0] += \" PRIMARY KEY\"\n",
    "        delete_query = sql.SQL('DROP TABLE IF EXISTS {0};').format(sql.Identifier(table))\n",
    "        query = sql.SQL(\n",
    "            \"CREATE TABLE {0} ({1});\"\n",
    "            ).format(\n",
    "                sql.Identifier(table),\n",
    "                sql.SQL(\",\".join(sanitized_cols))\n",
    "            )\n",
    "        print(query)\n",
    "        cur.execute(delete_query)\n",
    "        cur.execute(query)\n",
    "        return cur.query.decode(\"utf-8\")\n",
    "    \n",
    "    def upload(\n",
    "        self,\n",
    "        filepath: str,\n",
    "        table: str,\n",
    "        index_col: Optional[str] = None,\n",
    "        datetime_cols: Optional[List[str]] = None,\n",
    "    ):\n",
    "        \"\"\"Uploads a CSV file as its own table in a Postgres DB\n",
    "        Args:\n",
    "            filepath (str): Path to CSV file\n",
    "            table (str): Table name\n",
    "            index_col (Optional[str], optional): Name of index column. Defaults to None, in which case a numerical index is used.\n",
    "            datetime_cols (Optional[List[str]], optional): List of column names for \"datetime\" columns. Defaults to None.\n",
    "        \"\"\"\n",
    "        cur = self.conn.cursor()\n",
    "        self.create_table(filepath, table, index_col, datetime_cols)\n",
    "        self.buffer.seek(0)\n",
    "#         cur.copy_from(self.buffer, table, sep=',')\n",
    "        cur.copy_expert(f\"COPY {table} FROM STDIN WITH (FORMAT CSV)\", self.buffer)\n",
    "        self.conn.commit()\n",
    "\n",
    "\n",
    "\n",
    "    def create_table_schema(\n",
    "        self,\n",
    "        filepath: str,\n",
    "        index_col: Optional[str] = None,\n",
    "        datetime_cols: Optional[List[str]] = None\n",
    "    ) -> Dict[str, str]:\n",
    "        \"\"\"Generates a Postgres schema based on the Pandas dtypes of an input CSV file\n",
    "        Args:\n",
    "            filepath (str): Path to CSV file\n",
    "            index_col (Optional[str], optional): Name of index column. Defaults to None, in which case a numerical index is used.\n",
    "            datetime_cols (Optional[List[str]], optional): List of column names for \"datetime\" columns. Defaults to None.\n",
    "        Returns:\n",
    "            Dict[str, str]: Mapping from column name to postgres type name\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(filepath, parse_dates=datetime_cols)\n",
    "#         df.drop(\"description\", axis=1, inplace=True)\n",
    "#         df.drop(\"part_specs_mount_display_value\", axis=1, inplace=True)\n",
    "        if \"Unnamed: 0\" in df.columns: df.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "        if not index_col:\n",
    "            df = df.reset_index()\n",
    "            index_col = df.columns[0]\n",
    "        else:\n",
    "            df.insert(0, index_col, df.pop(index_col), allow_duplicates=True)\n",
    "        \n",
    "        df = df.infer_objects()\n",
    "#         df.fillna(df.dtypes.replace({'float64': 0.0, 'O': 'NULL'}), inplace=True)\n",
    "        df.to_csv(self.buffer, header=False, index=False) #, quotechar='\"', quoting=csv.QUOTE_NONNUMERIC)\n",
    "        cols_map = self.map_sql_dtypes(df)\n",
    "        return cols_map\n",
    "\n",
    "\n",
    "    def map_sql_dtypes(self, df: pd.DataFrame) -> List[Tuple[str, str]]:\n",
    "        \"\"\"Given a dataframe, map each of its columns to the appropriate Postgres type \n",
    "        Args:\n",
    "            df (pd.DataFrame): Input dataframe\n",
    "        Returns:\n",
    "            Dict[str, str]: Mapping from column name to postgres type name\n",
    "        \"\"\"\n",
    "        col_to_pgtype = []\n",
    "        for col in df.columns:\n",
    "            dtype = df[col].dtype.name\n",
    "\n",
    "            if 'time' in dtype and re.compile(r'\\[.*\\]$').search(dtype):\n",
    "                dtype = re.sub(r'\\[.*\\]$', '', dtype)\n",
    "            col_to_pgtype.append((col, self.py_2_sql_map[dtype]))\n",
    "        return col_to_pgtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8bea24a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composed([SQL('CREATE TABLE '), Identifier('mica'), SQL(' ('), SQL('\"index\" BIGINT PRIMARY KEY,\"_cache_id\" VARCHAR,\"description\" VARCHAR,\"part_category_id\" BIGINT,\"part_id\" BIGINT,\"part_manufacturer_id\" BIGINT,\"part_manufacturer_is_verified\" BOOLEAN,\"part_manufacturer_name\" VARCHAR,\"part_median_price_1000__cache_id\" VARCHAR,\"part_median_price_1000_converted_currency\" VARCHAR,\"part_median_price_1000_converted_price\" DOUBLE PRECISION,\"part_mpn\" VARCHAR,\"part_specs_capacitance_id\" BIGINT,\"part_specs_capacitance_display_value\" VARCHAR,\"part_specs_case_package_id\" DOUBLE PRECISION,\"part_specs_case_package_display_value\" VARCHAR,\"part_specs_depth_id\" DOUBLE PRECISION,\"part_specs_depth_display_value\" VARCHAR,\"part_specs_dielectricmaterial_id\" DOUBLE PRECISION,\"part_specs_dielectricmaterial_display_value\" VARCHAR,\"part_specs_features_id\" DOUBLE PRECISION,\"part_specs_features_display_value\" VARCHAR,\"part_specs_height_id\" DOUBLE PRECISION,\"part_specs_height_display_value\" VARCHAR,\"part_specs_height_seated_max__id\" DOUBLE PRECISION,\"part_specs_height_seated_max__display_value\" VARCHAR,\"part_specs_leaddiameter_id\" DOUBLE PRECISION,\"part_specs_leaddiameter_display_value\" VARCHAR,\"part_specs_leadfree_id\" DOUBLE PRECISION,\"part_specs_leadfree_display_value\" VARCHAR,\"part_specs_leadpitch_id\" DOUBLE PRECISION,\"part_specs_leadpitch_display_value\" VARCHAR,\"part_specs_length_id\" DOUBLE PRECISION,\"part_specs_length_display_value\" VARCHAR,\"part_specs_maxoperatingtemperature_id\" DOUBLE PRECISION,\"part_specs_maxoperatingtemperature_display_value\" VARCHAR,\"part_specs_militarystandard_id\" DOUBLE PRECISION,\"part_specs_militarystandard_display_value\" VARCHAR,\"part_specs_minoperatingtemperature_id\" DOUBLE PRECISION,\"part_specs_minoperatingtemperature_display_value\" VARCHAR,\"part_specs_mount_id\" DOUBLE PRECISION,\"part_specs_mount_display_value\" VARCHAR,\"part_specs_numberofpins_id\" DOUBLE PRECISION,\"part_specs_numberofpins_display_value\" DOUBLE PRECISION,\"part_specs_packaging_id\" DOUBLE PRECISION,\"part_specs_packaging_display_value\" VARCHAR,\"part_specs_radiationhardening_id\" DOUBLE PRECISION,\"part_specs_radiationhardening_display_value\" VARCHAR,\"part_specs_reachsvhc_id\" DOUBLE PRECISION,\"part_specs_reachsvhc_display_value\" VARCHAR,\"part_specs_rohs_id\" DOUBLE PRECISION,\"part_specs_rohs_display_value\" VARCHAR,\"part_specs_scheduleB_id\" DOUBLE PRECISION,\"part_specs_scheduleB_display_value\" DOUBLE PRECISION,\"part_specs_temperaturecoefficient_id\" DOUBLE PRECISION,\"part_specs_temperaturecoefficient_display_value\" VARCHAR,\"part_specs_termination_id\" DOUBLE PRECISION,\"part_specs_termination_display_value\" VARCHAR,\"part_specs_tolerance_id\" DOUBLE PRECISION,\"part_specs_tolerance_display_value\" VARCHAR,\"part_specs_voltage_id\" DOUBLE PRECISION,\"part_specs_voltage_display_value\" VARCHAR,\"part_specs_voltagerating_id\" DOUBLE PRECISION,\"part_specs_voltagerating_display_value\" VARCHAR,\"part_specs_voltagerating_dc__id\" DOUBLE PRECISION,\"part_specs_voltagerating_dc__display_value\" VARCHAR,\"part_specs_width_id\" DOUBLE PRECISION,\"part_specs_width_display_value\" VARCHAR,\"part_specs_leadlength_id\" DOUBLE PRECISION,\"part_specs_leadlength_display_value\" VARCHAR,\"part_specs_voltagerating_ac__id\" DOUBLE PRECISION,\"part_specs_voltagerating_ac__display_value\" VARCHAR,\"part_specs_casecode_imperial__id\" DOUBLE PRECISION,\"part_specs_casecode_imperial__display_value\" DOUBLE PRECISION,\"part_specs_casecode_metric__id\" DOUBLE PRECISION,\"part_specs_casecode_metric__display_value\" DOUBLE PRECISION,\"part_specs_dissipationfactor_id\" DOUBLE PRECISION,\"part_specs_dissipationfactor_display_value\" VARCHAR,\"part_specs_weight_id\" DOUBLE PRECISION,\"part_specs_weight_display_value\" VARCHAR,\"part_specs_workingvoltage_id\" DOUBLE PRECISION,\"part_specs_workingvoltage_display_value\" VARCHAR,\"part_specs_ripplecurrent_id\" DOUBLE PRECISION,\"part_specs_ripplecurrent_display_value\" VARCHAR,\"part_specs_dielectric_id\" DOUBLE PRECISION,\"part_specs_dielectric_display_value\" VARCHAR,\"part_median_price_1000\" DOUBLE PRECISION,\"part_specs_esr_equivalentseriesresistance__id\" DOUBLE PRECISION,\"part_specs_esr_equivalentseriesresistance__display_value\" VARCHAR'), SQL(');')])\n",
      "\n",
      "\n",
      "\n",
      "Time elapsed 1.8195410000043921s\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "\n",
    "host = \"ec2-34-233-115-14.compute-1.amazonaws.com\"\n",
    "port = 5432\n",
    "database = \"dfu56m15dkhh46\"\n",
    "user = \"pgyrjmstmyerfk\"\n",
    "password = \"228fcbba14e9d2bf362fcaa29cabe1106cc8dba00605f45ee25e810194309fd4\"\n",
    "\n",
    "conn = ps.connect(\n",
    "    host=host,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    port=port,\n",
    "    database=database\n",
    ")\n",
    "\n",
    "uploader = PostgresCSVUploader(conn)\n",
    "uploader.upload(\n",
    "    \"csv/mica.csv\",\n",
    "    \"mica\"\n",
    ")\n",
    "# ...\n",
    "end = timer()\n",
    "print(f\"\\n\\n\\nTime elapsed {end - start}s\") # Time in seconds, e.g. 5.38091952400282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a2f425f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PostgresCSVUploader' object has no attribute 'sanitized_cols'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(uploader\u001b[38;5;241m.\u001b[39mbuffer\u001b[38;5;241m.\u001b[39mreadline()\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43muploader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msanitized_cols\u001b[49m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uploader\u001b[38;5;241m.\u001b[39mbuffer\u001b[38;5;241m.\u001b[39mreadline()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)): \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#     if val not in (list)(zip(uploader.buffer.readline().split(','), uploader.sanitized_cols)): \u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PostgresCSVUploader' object has no attribute 'sanitized_cols'"
     ]
    }
   ],
   "source": [
    "print(len(uploader.buffer.readline().strip('\\n').split(',')))\n",
    "print(len(uploader.sanitized_cols))\n",
    "for i, val in enumerate(uploader.buffer.readline().split(',')): \n",
    "#     if val not in (list)(zip(uploader.buffer.readline().split(','), uploader.sanitized_cols)): \n",
    "    try:\n",
    "        print(i, val, uploader.sanitized_cols[i])\n",
    "    except: \n",
    "        print(i, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b0b1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747aaa11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab561878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36436249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1c8f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PostgresCSVUploader\n",
    "\n",
    "host = \"ec2-34-233-115-14.compute-1.amazonaws.com\"\n",
    "port = 5432\n",
    "database = \"dfu56m15dkhh46\"\n",
    "user = \"pgyrjmstmyerfk\"\n",
    "password = \"228fcbba14e9d2bf362fcaa29cabe1106cc8dba00605f45ee25e810194309fd4\"\n",
    "\n",
    "conn = ps.connect(\n",
    "    host=host,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    port=port,\n",
    "    database=database\n",
    ")\n",
    "uploader = PostgresCSVUploader(conn)\n",
    "uploader.upload(\n",
    "    \"csv/mica.csv\",\n",
    "    \"mica\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9297402d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6dc77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a4de91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ef73bc3",
   "metadata": {},
   "source": [
    "### Splitting Column into Number and Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3319f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_spec(df: pd.DataFrame) -> df: pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Computes a split \n",
    "    \"\"\"\n",
    "        \n",
    "    a = df\n",
    "    for col in df.columns:\n",
    "        \n",
    "    \n",
    "    # first go through all the columns\n",
    "    # then somehow detect when we hit a column whose value includes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "69e1a2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_cache_id</th>\n",
       "      <th>description</th>\n",
       "      <th>part_category_id</th>\n",
       "      <th>part_id</th>\n",
       "      <th>part_manufacturer_id</th>\n",
       "      <th>part_manufacturer_is_verified</th>\n",
       "      <th>part_manufacturer_name</th>\n",
       "      <th>part_median_price_1000__cache_id</th>\n",
       "      <th>part_median_price_1000_converted_currency</th>\n",
       "      <th>part_median_price_1000_converted_price</th>\n",
       "      <th>...</th>\n",
       "      <th>part_specs_weight_display_value</th>\n",
       "      <th>part_specs_workingvoltage_id</th>\n",
       "      <th>part_specs_workingvoltage_display_value</th>\n",
       "      <th>part_specs_ripplecurrent_id</th>\n",
       "      <th>part_specs_ripplecurrent_display_value</th>\n",
       "      <th>part_specs_dielectric_id</th>\n",
       "      <th>part_specs_dielectric_display_value</th>\n",
       "      <th>part_median_price_1000</th>\n",
       "      <th>part_specs_esr_equivalentseriesresistance__id</th>\n",
       "      <th>part_specs_esr_equivalentseriesresistance__display_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US-USD-133323</td>\n",
       "      <td>Capacitor, Mica, Cap 100pF, Tol 5%, Radial DIP...</td>\n",
       "      <td>6334</td>\n",
       "      <td>133323</td>\n",
       "      <td>87</td>\n",
       "      <td>False</td>\n",
       "      <td>Cornell Dubilier</td>\n",
       "      <td>US-USD-133323-1000-0.991000</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US-USD-887085</td>\n",
       "      <td>Capacitor, Mica, Cap 100pF, Tol 1%, Radial DIP...</td>\n",
       "      <td>6334</td>\n",
       "      <td>887085</td>\n",
       "      <td>87</td>\n",
       "      <td>False</td>\n",
       "      <td>Cornell Dubilier</td>\n",
       "      <td>US-USD-887085-1000-1.530000</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.5300</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US-USD-123206</td>\n",
       "      <td>Capacitor; Mica; Cap 100pF; Tol 5%; Radial Min...</td>\n",
       "      <td>6334</td>\n",
       "      <td>123206</td>\n",
       "      <td>87</td>\n",
       "      <td>False</td>\n",
       "      <td>Cornell Dubilier</td>\n",
       "      <td>US-USD-123206-1000-2.500000</td>\n",
       "      <td>USD</td>\n",
       "      <td>2.5000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US-USD-153098</td>\n",
       "      <td>Capacitor; Mica; Cap 100pF; Tol 5%; Radial DIP...</td>\n",
       "      <td>6334</td>\n",
       "      <td>153098</td>\n",
       "      <td>87</td>\n",
       "      <td>False</td>\n",
       "      <td>Cornell Dubilier</td>\n",
       "      <td>US-USD-153098-1000-1.908900</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.9089</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US-USD-136131</td>\n",
       "      <td>Capacitor; Mica; Cap 100 pF; Tol 5%; Vol-Rtg 5...</td>\n",
       "      <td>6334</td>\n",
       "      <td>136131</td>\n",
       "      <td>87</td>\n",
       "      <td>False</td>\n",
       "      <td>Cornell Dubilier</td>\n",
       "      <td>US-USD-136131-1000-1.880000</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.8800</td>\n",
       "      <td>...</td>\n",
       "      <td>26.988746 mg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       _cache_id                                        description  \\\n",
       "0  US-USD-133323  Capacitor, Mica, Cap 100pF, Tol 5%, Radial DIP...   \n",
       "1  US-USD-887085  Capacitor, Mica, Cap 100pF, Tol 1%, Radial DIP...   \n",
       "2  US-USD-123206  Capacitor; Mica; Cap 100pF; Tol 5%; Radial Min...   \n",
       "3  US-USD-153098  Capacitor; Mica; Cap 100pF; Tol 5%; Radial DIP...   \n",
       "4  US-USD-136131  Capacitor; Mica; Cap 100 pF; Tol 5%; Vol-Rtg 5...   \n",
       "\n",
       "   part_category_id  part_id  part_manufacturer_id  \\\n",
       "0              6334   133323                    87   \n",
       "1              6334   887085                    87   \n",
       "2              6334   123206                    87   \n",
       "3              6334   153098                    87   \n",
       "4              6334   136131                    87   \n",
       "\n",
       "   part_manufacturer_is_verified part_manufacturer_name  \\\n",
       "0                          False       Cornell Dubilier   \n",
       "1                          False       Cornell Dubilier   \n",
       "2                          False       Cornell Dubilier   \n",
       "3                          False       Cornell Dubilier   \n",
       "4                          False       Cornell Dubilier   \n",
       "\n",
       "  part_median_price_1000__cache_id part_median_price_1000_converted_currency  \\\n",
       "0      US-USD-133323-1000-0.991000                                       USD   \n",
       "1      US-USD-887085-1000-1.530000                                       USD   \n",
       "2      US-USD-123206-1000-2.500000                                       USD   \n",
       "3      US-USD-153098-1000-1.908900                                       USD   \n",
       "4      US-USD-136131-1000-1.880000                                       USD   \n",
       "\n",
       "   part_median_price_1000_converted_price  ...  \\\n",
       "0                                  0.9910  ...   \n",
       "1                                  1.5300  ...   \n",
       "2                                  2.5000  ...   \n",
       "3                                  1.9089  ...   \n",
       "4                                  1.8800  ...   \n",
       "\n",
       "  part_specs_weight_display_value  part_specs_workingvoltage_id  \\\n",
       "0                             NaN                           NaN   \n",
       "1                             NaN                           NaN   \n",
       "2                             NaN                           NaN   \n",
       "3                             NaN                           NaN   \n",
       "4                    26.988746 mg                           NaN   \n",
       "\n",
       "  part_specs_workingvoltage_display_value  part_specs_ripplecurrent_id  \\\n",
       "0                                     NaN                          NaN   \n",
       "1                                     NaN                          NaN   \n",
       "2                                     NaN                          NaN   \n",
       "3                                     NaN                          NaN   \n",
       "4                                     NaN                          NaN   \n",
       "\n",
       "  part_specs_ripplecurrent_display_value  part_specs_dielectric_id  \\\n",
       "0                                    NaN                       NaN   \n",
       "1                                    NaN                       NaN   \n",
       "2                                    NaN                       NaN   \n",
       "3                                    NaN                       NaN   \n",
       "4                                    NaN                       NaN   \n",
       "\n",
       "  part_specs_dielectric_display_value  part_median_price_1000  \\\n",
       "0                                 NaN                     NaN   \n",
       "1                                 NaN                     NaN   \n",
       "2                                 NaN                     NaN   \n",
       "3                                 NaN                     NaN   \n",
       "4                                 NaN                     NaN   \n",
       "\n",
       "  part_specs_esr_equivalentseriesresistance__id  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           NaN   \n",
       "4                                           NaN   \n",
       "\n",
       "   part_specs_esr_equivalentseriesresistance__display_value  \n",
       "0                                                NaN         \n",
       "1                                                NaN         \n",
       "2                                                NaN         \n",
       "3                                                NaN         \n",
       "4                                                NaN         \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_csv('csv/mica_min.csv')\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "34a36f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: 26.988746 Units:  milligram\n",
      "Value: 15.989131 Units:  milligram\n",
      "Value: 15.989131 Units:  milligram\n"
     ]
    }
   ],
   "source": [
    "import pint\n",
    "for row in d['part_specs_weight_display_value']:\n",
    "    ureg = pint.UnitRegistry()\n",
    "    quantity = ureg(str(row))\n",
    "    if type(quantity) is not float:\n",
    "        print(\"Value:\", quantity.magnitude, \"Units: \", quantity.units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0371f8e1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12908c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PART_SEARCH_QUERY = \"\"\"\n",
    "query PricesViewSearch($country: String!, $currency: String!, $filters: Map, $in_stock_only: \\\n",
    "  Boolean, $limit: Int!, $q: String, $sort: String, $sort_dir: SortDirection, $start: Int) {\n",
    "  search(country: $country, currency: $currency, filters: $filters, in_stock_only: $in_stock_only, \\\n",
    "    limit: $limit, q: $q, sort: $sort, sort_dir: $sort_dir, start: $start) {\n",
    "    applied_category {\n",
    "      ancestors {\n",
    "        id\n",
    "        name\n",
    "        path\n",
    "        __typename\n",
    "      }\n",
    "      id\n",
    "      name\n",
    "      path\n",
    "      __typename\n",
    "    }\n",
    "    applied_filters {\n",
    "      display_values\n",
    "      name\n",
    "      shortname\n",
    "      values\n",
    "      __typename\n",
    "    }\n",
    "    results {\n",
    "      _cache_id\n",
    "      description\n",
    "      part {\n",
    "        _cache_id\n",
    "        best_datasheet {\n",
    "          url\n",
    "          __typename\n",
    "        }\n",
    "        best_image {\n",
    "          url\n",
    "          __typename\n",
    "        }\n",
    "        category {\n",
    "          id\n",
    "          __typename\n",
    "        }\n",
    "        counts\n",
    "        descriptions {\n",
    "          text\n",
    "          __typename\n",
    "        }\n",
    "        id\n",
    "        manufacturer {\n",
    "          id\n",
    "          is_verified\n",
    "          name\n",
    "          __typename\n",
    "        }\n",
    "        manufacturer_url\n",
    "        median_price_1000 {\n",
    "          _cache_id\n",
    "          converted_currency\n",
    "          converted_price\n",
    "          __typename\n",
    "        }\n",
    "        mpn\n",
    "        specs {\n",
    "          attribute {\n",
    "            id\n",
    "            name\n",
    "            shortname\n",
    "            __typename\n",
    "          }\n",
    "          display_value\n",
    "          __typename\n",
    "        }\n",
    "        __typename\n",
    "      }\n",
    "      __typename\n",
    "    }\n",
    "    hits\n",
    "    __typename\n",
    "  }\n",
    "}\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "componet",
   "language": "python",
   "name": "componet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
